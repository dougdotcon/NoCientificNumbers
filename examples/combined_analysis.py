#!/usr/bin/env python3
"""
An√°lise Combinada: M√∫ltiplas Fontes de Dados

Este script combina dados de Wikidata, OWID e outras fontes
para uma an√°lise estat√≠stica mais robusta da hip√≥tese numerol√≥gica.
"""

import sys
import os
import pandas as pd

# Adicionar src ao path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from data_processor import NumerologyDataAnalyzer


def main():
    """An√°lise combinada de m√∫ltiplas fontes."""
    print("=== PyNumerology-Matrix: An√°lise Combinada de M√∫ltiplas Fontes ===\n")

    analyzer = NumerologyDataAnalyzer()

    # Coletar dados de m√∫ltiplas fontes
    all_events = []
    all_analysis = []

    sources = ['wikidata', 'owid']

    for source in sources:
        print(f"üîç Coletando dados de {source.upper()}...")
        try:
            results = analyzer.collect_and_analyze(source=source, limit=1000)

            if 'events_data' in results and not results['events_data'].empty:
                events_df = results['events_data']
                analysis_df = results['analysis_data']

                print(f"   ‚úÖ {len(events_df)} eventos coletados")
                print(f"   ‚úÖ {len(analysis_df)} eventos analisados")

                all_events.append(events_df)
                all_analysis.append(analysis_df)
            else:
                print(f"   ‚ùå Nenhum dado coletado de {source}")

        except Exception as e:
            print(f"   ‚ùå Erro em {source}: {e}")

    # Combinar todos os dados
    if not all_events:
        print("\n‚ùå Nenhum dado coletado de nenhuma fonte. Usando dados demo...")
        create_combined_demo(analyzer)
        return

    combined_events = pd.concat(all_events, ignore_index=True)
    combined_analysis = pd.concat(all_analysis, ignore_index=True)

    # Remover duplicatas se houver
    combined_events = combined_events.drop_duplicates()
    combined_analysis = combined_analysis.drop_duplicates()

    print(f"\nüìä TOTAL COMBINADO:")
    print(f"   Eventos √∫nicos: {len(combined_events)}")
    print(f"   An√°lises num.: {len(combined_analysis)}")
    print(f"   Fontes: {combined_events['source'].nunique()} diferentes")

    # An√°lise estat√≠stica combinada
    hypothesis = analyzer.test_hypothesis_ano_9(combined_analysis)
    decade_analysis = analyzer.analyze_by_decade(combined_analysis)

    print(f"\nüéØ TESTE ESTAT√çSTICO COMBINADO ({len(combined_analysis)} eventos):")
    print("=" * 60)
    print(f"Total de eventos: {hypothesis['total_events']}")
    print(f"Eventos no Ano 9: {hypothesis['ano_9_count']} ({hypothesis['ano_9_percentage']}%)")
    print(f"Esperado (uniforme): {hypothesis['expected_uniform']:.1f}")
    print(f"Desvio: {hypothesis['deviation']:.1f}")
    print(f"Z-Score: {hypothesis['z_score']:.2f}")
    print(f"Qui-quadrado: {hypothesis['chi_square_stat']:.2f} (p={hypothesis['p_value']:.4f})")

    if hypothesis['distribution_uniform']:
        print("Distribui√ß√£o: UNIFORME (estatisticamente)")
    else:
        print("Distribui√ß√£o: N√ÉO UNIFORME (p < 0.05)")

    if hypothesis['hypothesis_supported']:
        print("HIP√ìTESE: SUPORTADA estatisticamente!")
    else:
        print("HIP√ìTESE: N√ÉO suportada estatisticamente")

    # Distribui√ß√£o detalhada
    print(f"\nüìà DISTRIBUI√á√ÉO POR ANO PESSOAL:")
    expected_pct = 100/9
    for ano in range(1, 10):
        count = hypothesis['counts_by_ano'].get(ano, 0)
        actual_pct = count / hypothesis['total_events'] * 100
        marker = "üî¥" if actual_pct > expected_pct * 1.2 else "üü¢" if actual_pct < expected_pct * 0.8 else "üü°"
        print(f"   Ano {ano}: {count:3d} eventos ({actual_pct:5.1f}%) {marker}")

    # An√°lise por fonte
    print(f"\nüìä AN√ÅLISE POR FONTE:")
    for source in combined_analysis['source'].unique():
        source_data = combined_analysis[combined_analysis['source'] == source]
        if len(source_data) > 10:
            ano_9_pct = (source_data['ano_pessoal'] == 9).sum() / len(source_data) * 100
            print(f"   {source}: {len(source_data)} eventos, Ano 9: {ano_9_pct:.1f}%")

    # An√°lise por d√©cada
    if decade_analysis:
        print(f"\nüìÖ AN√ÅLISE POR D√âCADA (Ano 9 %):")
        for decade in sorted(decade_analysis.keys()):
            stats = decade_analysis[decade]
            if stats['total_events'] >= 20:  # S√≥ d√©cadas com dados suficientes
                marker = "üî¥" if stats['ano_9_percentage'] > 13 else "üü¢" if stats['ano_9_percentage'] < 7 else "üü°"
                print(f"   {decade}s: {marker} {stats['ano_9_percentage']:.1f}% ({stats['ano_9_count']}/{stats['total_events']})")

    # Salvar dados combinados
    output_dir = os.path.join(os.path.dirname(__file__), '..', 'data')
    os.makedirs(output_dir, exist_ok=True)

    combined_events.to_csv(os.path.join(output_dir, 'combined_events.csv'), index=False)
    combined_analysis.to_csv(os.path.join(output_dir, 'combined_analysis.csv'), index=False)

    print(f"\nüíæ Dados salvos em: {output_dir}")

    # Conclus√£o
    print(f"\nüî¨ CONCLUS√ÉO CIENT√çFICA:")
    if hypothesis['p_value'] > 0.05:
        print("   Com base em dados de m√∫ltiplas fontes cient√≠ficas,")
        print("   N√ÉO h√° evid√™ncia estat√≠stica de que eventos disruptivos")
        print("   concentrem-se em Anos Pessoais 9. A distribui√ß√£o √© uniforme.")
    else:
        print("   Dados indicam POSS√çVEL padr√£o n√£o-uniforme, mas s√£o")
        print("   necess√°rios mais dados para confirma√ß√£o estat√≠stica.")


def create_combined_demo(analyzer):
    """Cria demonstra√ß√£o com dados combinados simulados."""
    print("Criando an√°lise demo com dados hist√≥ricos conhecidos...")

    # Dados hist√≥ricos conhecidos com anos disruptivos
    demo_events = [
        # Guerras Mundiais
        {'year': 1914, 'event': 'In√≠cio WWI', 'type': 'Guerra'},
        {'year': 1918, 'event': 'Fim WWI', 'type': 'Guerra'},
        {'year': 1939, 'event': 'In√≠cio WWII', 'type': 'Guerra'},
        {'year': 1945, 'event': 'Fim WWII', 'type': 'Guerra'},

        # Crises econ√¥micas
        {'year': 1929, 'event': 'Quebra da Bolsa', 'type': 'Crise Econ√¥mica'},
        {'year': 2008, 'event': 'Crise Financeira Global', 'type': 'Crise Econ√¥mica'},

        # Eventos disruptivos diversos
        {'year': 1969, 'event': 'Chegada √† Lua', 'type': 'Avan√ßo Tecnol√≥gico'},
        {'year': 1989, 'event': 'Queda Muro de Berlin', 'type': 'Mudan√ßa Pol√≠tica'},
        {'year': 2020, 'event': 'Pandemia COVID-19', 'type': 'Crise Global'},
    ] * 10  # Multiplicar para ter mais dados

    events_df = pd.DataFrame(demo_events)
    analysis_df = analyzer.analyze_event_cycles(events_df)
    hypothesis = analyzer.test_hypothesis_ano_9(analysis_df)

    print(f"\n[DEMO] An√°lise com {len(analysis_df)} eventos hist√≥ricos conhecidos")
    print(f"[DEMO] Ano 9: {hypothesis['ano_9_count']}/{hypothesis['total_events']} ({hypothesis['ano_9_percentage']}%)")
    print(f"[DEMO] Distribui√ß√£o uniforme: {hypothesis['distribution_uniform']}")
    print(f"[DEMO] Hip√≥tese suportada: {hypothesis['hypothesis_supported']}")


if __name__ == "__main__":
    main()